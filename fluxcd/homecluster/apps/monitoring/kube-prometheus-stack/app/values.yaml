## Install Prometheus Operator CRDs
##
crds:
  enabled: true
  ## The CRD upgrade job mitigates the limitation of helm not being able to upgrade CRDs.
  ## The job will apply the CRDs to the cluster before the operator is deployed, using helm hooks.
  ## It deploy a corresponding clusterrole, clusterrolebinding and serviceaccount to apply the CRDs.
  ## This feature is in preview, off by default and may change in the future.
  upgradeJob:
    enabled: true
    forceConflicts: true

global:
  rbac:
    create: true
    createAggregateClusterRoles: false
    pspEnabled: false
    pspAnnotations: {}

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:
  ## Deploy alertmanager
  ##
  enabled: true
  ## Create dashboard configmap even if alertmanager deployment has been disabled
  ##
  forceDeployDashboards: true

  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-production
    hosts:
      - alertmanager.home.inherently.xyz
    paths:
      - /
    pathType: ImplementationSpecific
    tls:
      - secretName: alertmanager-tls
        hosts:
          - alertmanager.home.inherently.xyz

  ## Settings affecting alertmanagerSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#alertmanagerspec
  ##
  alertmanagerSpec:
    ## Statefulset's persistent volume claim retention policy
    ## whenDeleted and whenScaled determine whether
    ## statefulset's PVCs are deleted (true) or retained (false)
    ## on scaling down and deleting statefulset, respectively.
    ## Requires Kubernetes version 1.27.0+.
    ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain

    ## Time duration Alertmanager shall retain data for. Default is '120h', and must match the regular expression
    ## [0-9]+(ms|s|m|h) (milliseconds seconds minutes hours).
    ##
    retention: 1500h
    ## Storage is the definition of how storage will be used by the Alertmanager instances.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/platform/storage.md
    ##
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: openebs-triple-replica
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
    ## The external URL the Alertmanager instances will be available under. This is necessary to generate correct URLs. This is necessary if Alertmanager is not served from root of a DNS name. string  false
    ##
    externalUrl: https://alertmanager.home.inherently.xyz

## Using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
##
grafana:
  enabled: true

  ## ForceDeployDatasources Create datasource configmap even if grafana deployment has been disabled
  ##
  forceDeployDatasources: true

  ## ForceDeployDashboard Create dashboard configmap even if grafana deployment has been disabled
  ##
  forceDeployDashboards: true

  ## Deploy default dashboards
  ##
  defaultDashboardsEnabled: true

  ## Timezone for the default dashboards
  ## Other options are: browser or a specific timezone, i.e. Europe/Luxembourg
  ##
  defaultDashboardsTimezone: browser

  ## Editable flag for the default dashboards
  ##
  defaultDashboardsEditable: true

  adminUser: admin
  adminPassword: prom-operator

  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-production
    hosts:
      - grafana.home.inherently.xyz
    path: /
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.home.inherently.xyz

  # To make Grafana persistent (Using Statefulset)
  #
  persistence:
    enabled: true
    type: sts
    storageClassName: "openebs-triple-replica"
    accessModes:
      - ReadWriteOnce
    size: 20Gi
    finalizers:
      - kubernetes.io/pvc-protection

    datasources:
      enabled: true
      defaultDatasourceEnabled: true
      isDefaultDatasource: true
      name: Prometheus
      uid: prometheus

      ## URL of prometheus datasource
      ##
      url: https://prometheus.home.inherently.xyz/

      alertmanager:
        enabled: true
        name: Alertmanager
        uid: alertmanager
        handleGrafanaManagedAlerts: true
        implementation: prometheus

## Flag to disable all the kubernetes component scrapers
##
kubernetesServiceMonitors:
  enabled: true
## Component scraping the kubelet and kubelet-hosted cAdvisor
##
kubelet:
  enabled: true
  serviceMonitor:
    enabled: true
    ## Enable scraping /metrics from kubelet's service
    kubelet: true
    ## Enable scraping the kubelet over https. For requirements to enable this see
    ## https://github.com/prometheus-operator/prometheus-operator/issues/926
    ##
    https: true
    ## Skip TLS certificate validation when scraping.
    ## This is enabled by default because kubelet serving certificate deployed by kubeadm is by default self-signed
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/#kubelet-serving-certs
    ##
    insecureSkipVerify: true
## Component scraping the kube api server
##
kubeApiServer:
  enabled: true
## Component scraping the kube controller manager
##
kubeControllerManager:
  enabled: false
## Component scraping etcd
##
kubeEtcd:
  enabled: false
## Component scraping kube scheduler
##
kubeScheduler:
  enabled: false
## Component scraping kube proxy
##
kubeProxy:
  enabled: false
## Component scraping kube state metrics
##
kubeStateMetrics:
  enabled: true
## Configuration for kube-state-metrics subchart
##
kube-state-metrics:
  ## Enable scraping via kubernetes-service-endpoints
  ## Disabled by default as we service monitor is enabled below
  ##
  prometheusScrape: false


## Deploy node exporter as a daemonset to all nodes
##
nodeExporter:
  enabled: true
  operatingSystems:
    linux:
      enabled: true
    aix:
      enabled: false
    darwin:
      enabled: false
  ## ForceDeployDashboard Create dashboard configmap even if nodeExporter deployment has been disabled
  ##
  forceDeployDashboards: true

## Configuration for prometheus-node-exporter subchart
##
prometheus-node-exporter:
  releaseLabel: true
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$


## Manages Prometheus and Alertmanager components
##
prometheusOperator:
  enabled: true
  ## Use '{{ template "kube-prometheus-stack.fullname" . }}-operator' by default
  fullnameOverride: ""

## Deploy a Prometheus instance
##
prometheus:
  enabled: true

  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-production
    hosts:
      - prometheus.home.inherently.xyz
    paths:
      - /
    pathType: ImplementationSpecific
    tls:
      - secretName: prometheus-tls
        hosts:
          - prometheus.home.inherently.xyz

  ## Settings affecting prometheusSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#prometheusspec
  ##
  prometheusSpec:
    ## Statefulset's persistent volume claim retention policy
    ## whenDeleted and whenScaled determine whether
    ## statefulset's PVCs are deleted (true) or retained (false)
    ## on scaling down and deleting statefulset, respectively.
    ## Requires Kubernetes version 1.27.0+.
    ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    ## EnableAdminAPI enables Prometheus the administrative HTTP API which includes functionality such as deleting time series.
    ## This is disabled by default.
    ## ref: https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis
    ##
    enableAdminAPI: true
    ## External URL at which Prometheus will be reachable.
    ##
    externalUrl: "https://prometheus.home.inherently.xyz"
    ## How long to retain metrics
    ##
    retention: 150d
    ## Maximum size of metrics
    ##
    retentionSize: "50GB"
    ## Enable/Disable Grafana dashboards provisioning for prometheus remote write feature
    remoteWriteDashboards: true
    ## Prometheus StorageSpec for persistent data
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/platform/storage.md
    ##
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: openebs-triple-replica
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 70Gi
    ## Enable compression of the write-ahead log using Snappy.
    ##
    walCompression: true

## Setting to true produces cleaner resource names, but requires a data migration because the name of the persistent volume changes. Therefore this should only be set once on initial installation.
##
cleanPrometheusOperatorObjectNames: false
